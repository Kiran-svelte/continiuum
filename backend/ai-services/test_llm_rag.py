"""
Test LLM-RAG Integration
This script tests all AI services with LLM support
"""
import requests
import json

BASE_URLS = {
    "leave": "http://localhost:8001",
    "recruitment": "http://localhost:8004",
    "onboarding": "http://localhost:8003",
    "performance": "http://localhost:8006"
}

def print_header(title):
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)

def test_health(service_name, url):
    """Test health endpoint"""
    try:
        response = requests.get(f"{url}/health", timeout=5)
        data = response.json()
        
        print(f"\n‚úÖ {service_name.upper()} Service:")
        print(f"   Status: {data.get('status', 'unknown')}")
        print(f"   RAG Status: {data.get('rag_status', 'unknown')}")
        print(f"   LLM Status: {data.get('llm_status', 'unknown')}")
        print(f"   LLM Provider: {data.get('llm_provider', 'none')}")
        print(f"   LLM Model: {data.get('llm_model', 'none')}")
        
        return data.get('llm_status') == 'ready'
    except Exception as e:
        print(f"\n‚ùå {service_name.upper()} Service: {str(e)}")
        return False

def test_leave_chat():
    """Test Leave Agent chat endpoint"""
    print_header("TEST 1: Leave Agent - LLM Chat")
    
    try:
        response = requests.post(
            f"{BASE_URLS['leave']}/chat",
            json={"question": "How many sick leave days do I get per year?"},
            timeout=30
        )
        
        if response.status_code == 503:
            print("\n‚ö†Ô∏è LLM not configured. Please set GROQ_API_KEY or OPENAI_API_KEY")
            print("   Get free Groq API key: https://console.groq.com/keys")
            return False
        
        data = response.json()
        
        print(f"\nüìù Question: How many sick leave days do I get per year?")
        print(f"\nü§ñ Answer:\n{data.get('answer', 'No answer')}")
        print(f"\nüìä Metadata:")
        print(f"   Confidence: {data.get('confidence', 0)}%")
        print(f"   RAG Matches: {data.get('rag_matches', 0)}")
        print(f"   LLM Provider: {data.get('llm_provider', 'unknown')}")
        print(f"   LLM Model: {data.get('llm_model', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        return False

def test_recruitment_questions():
    """Test Recruitment Agent question generation"""
    print_header("TEST 2: Recruitment Agent - Interview Questions")
    
    try:
        response = requests.post(
            f"{BASE_URLS['recruitment']}/questions",
            json={"role": "Senior Python Developer"},
            timeout=30
        )
        
        data = response.json()
        
        print(f"\nüìù Role: Senior Python Developer")
        print(f"\n‚ùì Generated Questions:")
        for i, q in enumerate(data.get('questions', []), 1):
            print(f"   {i}. {q}")
        
        print(f"\nüìä Generated by: {data.get('generated_by', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        return False

def test_recruitment_analysis():
    """Test Recruitment Agent candidate analysis"""
    print_header("TEST 3: Recruitment Agent - Candidate Analysis")
    
    try:
        response = requests.post(
            f"{BASE_URLS['recruitment']}/analyze",
            json={
                "role": "Senior Developer",
                "exp": 5,
                "skills": ["Python", "React", "AWS"]
            },
            timeout=30
        )
        
        if response.status_code == 503:
            print("\n‚ö†Ô∏è LLM not configured")
            return False
        
        data = response.json()
        
        print(f"\nüë§ Candidate Profile:")
        print(f"   Role: Senior Developer")
        print(f"   Experience: 5 years")
        print(f"   Skills: Python, React, AWS")
        
        print(f"\nü§ñ Analysis:\n{data.get('analysis', 'No analysis')}")
        print(f"\nüìä Similar Candidates Found: {data.get('similar_candidates_found', 0)}")
        
        return True
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        return False

def test_onboarding_ask():
    """Test Onboarding Agent"""
    print_header("TEST 4: Onboarding Agent - Q&A")
    
    try:
        response = requests.post(
            f"{BASE_URLS['onboarding']}/ask",
            json={"question": "What should I do on my first day?"},
            timeout=30
        )
        
        data = response.json()
        
        print(f"\nüìù Question: What should I do on my first day?")
        print(f"\nü§ñ Answer:\n{data.get('answer', 'No answer')}")
        print(f"\nüìä Mode: {data.get('mode', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        return False

def test_performance_predict():
    """Test Performance Agent prediction"""
    print_header("TEST 5: Performance Agent - Prediction")
    
    try:
        response = requests.post(
            f"{BASE_URLS['performance']}/predict",
            json={"rating": 4.2, "hours": 45, "projects": 3},
            timeout=30
        )
        
        data = response.json()
        
        print(f"\nüë§ Employee Data:")
        print(f"   Current Rating: 4.2/5.0")
        print(f"   Weekly Hours: 45")
        print(f"   Projects Completed: 3")
        
        print(f"\nü§ñ Analysis:\n{data.get('analysis', 'No analysis')}")
        print(f"\nüìä Mode: {data.get('mode', 'unknown')}")
        
        return True
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        return False

def main():
    """Run all tests"""
    print("\n" + "=" * 70)
    print("  üß™ LLM-RAG INTEGRATION TEST SUITE")
    print("=" * 70)
    
    # Test health endpoints
    print_header("HEALTH CHECKS")
    llm_available = {}
    for service, url in BASE_URLS.items():
        llm_available[service] = test_health(service, url)
    
    # Check if any LLM is configured
    any_llm = any(llm_available.values())
    
    if not any_llm:
        print("\n" + "=" * 70)
        print("  ‚ö†Ô∏è WARNING: NO LLM CONFIGURED")
        print("=" * 70)
        print("\n  To enable LLM features:")
        print("  1. Get free Groq API key: https://console.groq.com/keys")
        print("  2. Set environment variable:")
        print("     PowerShell: $env:GROQ_API_KEY = 'your_key_here'")
        print("  3. Restart AI services")
        print("\n  Tests will continue with fallback mode...")
    
    # Run functional tests
    results = []
    
    results.append(("Leave Agent Chat", test_leave_chat()))
    results.append(("Recruitment Questions", test_recruitment_questions()))
    results.append(("Recruitment Analysis", test_recruitment_analysis()))
    results.append(("Onboarding Q&A", test_onboarding_ask()))
    results.append(("Performance Prediction", test_performance_predict()))
    
    # Summary
    print_header("TEST SUMMARY")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
    
    print(f"\n  Total: {passed}/{total} tests passed")
    
    if passed == total:
        print("\n  üéâ ALL TESTS PASSED!")
    elif passed > 0:
        print("\n  ‚ö†Ô∏è SOME TESTS FAILED (check LLM configuration)")
    else:
        print("\n  ‚ùå ALL TESTS FAILED (check if services are running)")
    
    print("\n" + "=" * 70)

if __name__ == "__main__":
    main()
